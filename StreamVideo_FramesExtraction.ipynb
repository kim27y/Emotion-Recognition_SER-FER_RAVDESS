{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1fa0f050",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4af0d7f",
   "metadata": {},
   "source": [
    "Features\n",
    "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "- Vocal channel (01 = speech, 02 = song).\n",
    "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "- Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe300568",
   "metadata": {},
   "source": [
    "NB We considered only the speech videos (vocal channel=01) with both audio and video (modality=01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d260a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:37.510784Z",
     "start_time": "2023-01-01T17:27:37.486950Z"
    }
   },
   "outputs": [],
   "source": [
    "emotions = {1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}\n",
    "emotional_intensity = {1:'normal', 2:'strong'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bc976d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:13.200431Z",
     "start_time": "2023-01-01T17:27:10.028517Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 23:48:46.698475: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56d503e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:20.350634Z",
     "start_time": "2023-01-01T17:27:20.329824Z"
    }
   },
   "outputs": [],
   "source": [
    "path = \"Datasets/AUDIO/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526e8cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:27.666721Z",
     "start_time": "2023-01-01T17:27:27.647035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01-01-04-01-02-02-20',\n",
       " '01-01-04-02-02-02-20',\n",
       " '01-01-05-02-01-02-20',\n",
       " '02-01-05-02-01-02-20',\n",
       " '02-01-05-02-01-02-20']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = []\n",
    "feats = []\n",
    "labels = []\n",
    "paths = []\n",
    "\n",
    "for (dirpath, dirnames, fn) in os.walk(path):\n",
    "    for name in fn:\n",
    "        filename = name.split('.')[0]\n",
    "        feat = filename.split('-')[2:]\n",
    "        label = feat[0]\n",
    "        filenames.append(filename)\n",
    "        feats.append(feat)\n",
    "        labels.append(label)\n",
    "        paths.append(dirpath + '/' + filename)\n",
    "        \n",
    "filenames[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce701ade",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f05715f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T17:27:40.031915Z",
     "start_time": "2023-01-01T17:27:40.012195Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotional intensity</th>\n",
       "      <th>statement</th>\n",
       "      <th>repetition</th>\n",
       "      <th>actor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01-01-04-01-02-02-20</th>\n",
       "      <td>sad</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-04-02-02-02-20</th>\n",
       "      <td>sad</td>\n",
       "      <td>strong</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-05-02-01-02-20</th>\n",
       "      <td>angry</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02-01-05-02-01-02-20</th>\n",
       "      <td>angry</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02-01-05-02-01-02-20</th>\n",
       "      <td>angry</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02-01-07-01-01-02-23</th>\n",
       "      <td>disgust</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-02-02-02-01-23</th>\n",
       "      <td>calm</td>\n",
       "      <td>strong</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-03-02-01-02-23</th>\n",
       "      <td>happy</td>\n",
       "      <td>strong</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02-01-08-02-02-02-23</th>\n",
       "      <td>surprise</td>\n",
       "      <td>strong</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01-01-01-01-02-02-23</th>\n",
       "      <td>neutral</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       emotion emotional intensity  statement  repetition  \\\n",
       "index                                                                       \n",
       "01-01-04-01-02-02-20       sad              normal          2           2   \n",
       "01-01-04-02-02-02-20       sad              strong          2           2   \n",
       "01-01-05-02-01-02-20     angry              strong          1           2   \n",
       "02-01-05-02-01-02-20     angry              strong          1           2   \n",
       "02-01-05-02-01-02-20     angry              strong          1           2   \n",
       "...                        ...                 ...        ...         ...   \n",
       "02-01-07-01-01-02-23   disgust              normal          1           2   \n",
       "01-01-02-02-02-01-23      calm              strong          2           1   \n",
       "01-01-03-02-01-02-23     happy              strong          1           2   \n",
       "02-01-08-02-02-02-23  surprise              strong          2           2   \n",
       "01-01-01-01-02-02-23   neutral              normal          2           2   \n",
       "\n",
       "                      actor  \n",
       "index                        \n",
       "01-01-04-01-02-02-20     20  \n",
       "01-01-04-02-02-02-20     20  \n",
       "01-01-05-02-01-02-20     20  \n",
       "02-01-05-02-01-02-20     20  \n",
       "02-01-05-02-01-02-20     20  \n",
       "...                     ...  \n",
       "02-01-07-01-01-02-23     23  \n",
       "01-01-02-02-02-01-23     23  \n",
       "01-01-03-02-01-02-23     23  \n",
       "02-01-08-02-02-02-23     23  \n",
       "01-01-01-01-02-02-23     23  \n",
       "\n",
       "[1440 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(feats, columns = ['emotion', 'emotional intensity', 'statement', 'repetition', 'actor']).astype(int)\n",
    "\n",
    "df['emotion'] = df['emotion'].map(emotions)\n",
    "df['emotional intensity'] = df['emotional intensity'].map(emotional_intensity)\n",
    "\n",
    "df['index'] = filenames\n",
    "df.set_index('index', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c49f7368",
   "metadata": {},
   "source": [
    "## Export frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d10ae3e3",
   "metadata": {},
   "source": [
    "- one frame every skip=3 starting from the 21th frame\n",
    "- proportional resize to obtain height=224\n",
    "- saved as png with and name videoname_iframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7a032a1",
   "metadata": {},
   "source": [
    "### 398x224 normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6955a9f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T18:28:26.762954Z",
     "start_time": "2023-01-01T18:28:26.754434Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    nframes_tot = 0\n",
    "    \n",
    "    for count, video in tqdm(enumerate(zip(filenames, paths)), desc='framing progress', bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'):\n",
    "        # Gather all its frames\n",
    "        # save_frames(video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames'), skip)\n",
    "        # print(f\"Processed videos {count+1}/{len(paths)}\")\n",
    "        time.sleep(5)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_frames(filename, input_path, output_path, skip):\n",
    "    # Initialize video reader\n",
    "    cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "    frames = []\n",
    "    count = 0\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    try:\n",
    "        # Loop through all frames\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if (count % skip == 0 and count > 20):\n",
    "                #print(frame.shape)\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, (398, 224))\n",
    "                cv2.imwrite(output_path + '/' + f'{filename}_{count}' + '.png', frame)\n",
    "            count += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    \n",
    "    for count, video in enumerate(zip(filenames, paths)):\n",
    "        # Gather all its frames\n",
    "        filename, input_path, output_path = video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames')\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "        count = 0\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "            \n",
    "        try:\n",
    "        # Loop through all frames\n",
    "            while True:\n",
    "                # Capture frame\n",
    "                ret, frame = cap.read()\n",
    "                if (count % skip == 0 and count > 20):\n",
    "                    #print(frame.shape)\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    frame = cv2.resize(frame, (398, 224))\n",
    "                    cv2.imwrite(os.path.join(output_path, f'{filename}_{count}.png'), frame)\n",
    "                count += 1\n",
    "        finally:\n",
    "            cap.release()\n",
    "        print(f\"Processed videos {count+1}/{len(paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed1c48ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-01T18:48:13.241324Z",
     "start_time": "2023-01-01T18:34:00.912543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "framing progress: |          | 5/? [00:25<00:00,  5.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prepare_all_videos(filenames, paths, skip\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m, in \u001b[0;36mprepare_all_videos\u001b[0;34m(filenames, paths, skip)\u001b[0m\n\u001b[1;32m      3\u001b[0m nframes_tot \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m count, video \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(filenames, paths)), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mframing progress\u001b[39m\u001b[39m'\u001b[39m, bar_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{l_bar}\u001b[39;00m\u001b[39m{bar}\u001b[39;00m\u001b[39m| \u001b[39m\u001b[39m{n_fmt}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{total_fmt}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{elapsed}\u001b[39;00m\u001b[39m<\u001b[39m\u001b[39m{remaining}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{rate_fmt}\u001b[39;00m\u001b[39m{postfix}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[39m# Gather all its frames\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[39m# save_frames(video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames'), skip)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[39m# print(f\"Processed videos {count+1}/{len(paths)}\")\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     10\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prepare_all_videos(filenames, paths, skip=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a39bcd8f",
   "metadata": {},
   "source": [
    "### 224x224 black background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a198bdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    nframes_tot = 0\n",
    "    \n",
    "    for count, video in enumerate(zip(filenames, paths)):\n",
    "        # Gather all its frames\n",
    "        filename, input_path, output_path = video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames_black')\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "        count = 0\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "            \n",
    "        try:\n",
    "        # Loop through all frames\n",
    "            while True:\n",
    "                # Capture frame\n",
    "                ret, frame = cap.read()\n",
    "                if (count % skip == 0 and count > 20):\n",
    "                    #print(frame.shape)\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    #####\n",
    "                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                  # background from white to black\n",
    "                    ret, thresh = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "                    frame[thresh == 255] = 0\n",
    "                    #####\n",
    "                    frame = cv2.resize(frame, (398, 224))\n",
    "                    frame = frame[0:224, 87:311]\n",
    "                    cv2.imwrite(os.path.join(output_path, f'{filename}_{count}.png'), frame)\n",
    "                count += 1\n",
    "        finally:\n",
    "            cap.release()\n",
    "        \n",
    "        print(f\"Processed videos {count+1}/{len(paths)}\")\n",
    "\n",
    "\n",
    "\n",
    "def save_frames(filename, input_path, output_path, skip):\n",
    "    # Initialize video reader\n",
    "    cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "    frames = []\n",
    "    count = 0\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    try:\n",
    "        # Loop through all frames\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if (count % skip == 0 and count > 20):\n",
    "                #print(frame.shape)\n",
    "                if not ret:\n",
    "                    break\n",
    "                #####\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)                  # background from white to black\n",
    "                ret, thresh = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "                frame[thresh == 255] = 0\n",
    "                #####\n",
    "                frame = cv2.resize(frame, (398, 224))\n",
    "                frame = frame[0:224, 87:311]\n",
    "                cv2.imwrite(output_path + '/' + f'{filename}_{count}' + '.png', frame)\n",
    "            count += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_all_videos(filenames, paths, skip=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b84b0c65",
   "metadata": {},
   "source": [
    "### 224x224 only faces BW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a08142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    nframes_tot = 0\n",
    "    \n",
    "    for count, video in enumerate(zip(filenames, paths)):\n",
    "        # Gather all its frames\n",
    "        save_frames(video[0], video[1], video[1], skip)\n",
    "        print(f\"Processed videos {count+1}/{len(paths)}\")\n",
    "    return\n",
    "\n",
    "\n",
    "def save_frames(filename, input_path, output_path, skip):\n",
    "    # Initialize video reader\n",
    "    cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "    haar_cascade = cv2.CascadeClassifier('./Other/haarcascade_frontalface_default.xml')\n",
    "    frames = []\n",
    "    count = 0\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    try:\n",
    "        # Loop through all frames\n",
    "        while True:\n",
    "            # Capture frame\n",
    "            ret, frame = cap.read()\n",
    "            if os.path.exists(output_path + '/' + f'{filename}_{count}' + '.png'):\n",
    "                count += 1\n",
    "                continue\n",
    "            if (count % skip == 0 and count > 20):\n",
    "                #print(frame.shape)\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.12, minNeighbors=9)\n",
    "                # if len(faces) != 1:\n",
    "                    \n",
    "                if len(faces) == 0:\n",
    "                    faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.02, minNeighbors=9)\n",
    "                    if len(faces) == 0:\n",
    "                        print(f\"error {filename} {count} 발생!\")\n",
    "                        break\n",
    "                if len(faces) > 1:\n",
    "                    ex = []\n",
    "                    print(type(faces))\n",
    "                    for elem in faces:\n",
    "                        for (x, y, w, h) in [elem]:\n",
    "                            ex.append(frame[y:y + h, x:x + w])\n",
    "\n",
    "                    print(filename)\n",
    "                    # inp = int(input())\n",
    "                    # faces = [faces[inp]]\n",
    "                #     raise Exception(f\"More than 1 faces detected in {filename}\")\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    face = frame[y:y + h, x:x + w]\n",
    "\n",
    "                face = cv2.resize(face, (234, 234))\n",
    "                face = face[5:-5, 5:-5]\n",
    "                cv2.imwrite(output_path + '/' + f'{filename}_{count}' + '.png', face)\n",
    "                before_face = face\n",
    "            count += 1\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(filenames, paths, skip=1):\n",
    "    \n",
    "    for count, video in tqdm(enumerate(zip(filenames, paths)), desc='blacking progress', bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'):\n",
    "        # Gather all its frames\n",
    "        filename, input_path, output_path = video[0], video[1], video[1].replace('RAVDESS', 'RAVDESS_frames_face_BW')\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        \n",
    "        haar_cascade = cv2.CascadeClassifier('./Other/haarcascade_frontalface_default.xml')\n",
    "        count = 0\n",
    "        \n",
    "        while os.path.exist(os.path.join(output_path, f'{filename}_{count}.png')):\n",
    "            count += skip\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_path + '.mp4')\n",
    "        \n",
    "        try:\n",
    "        # Loop through all frames\n",
    "            while True:\n",
    "                # Capture frame\n",
    "                ret, frame = cap.read()\n",
    "                if os.path.exists(output_path + '/' + f'{filename}_{count}' + '.png'):\n",
    "                    count += 1\n",
    "                    continue\n",
    "                if (count % skip == 0 and count > 20):\n",
    "                    #print(frame.shape)\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                    faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.12, minNeighbors=9)\n",
    "                    # if len(faces) != 1:\n",
    "                        \n",
    "                    if len(faces) == 0:\n",
    "                        faces = haar_cascade.detectMultiScale(frame, scaleFactor=1.02, minNeighbors=9)\n",
    "                        if len(faces) == 0:\n",
    "                            print(f\"error {filename} {count} 발생!, 얼굴 인식 불가!\")\n",
    "                            break\n",
    "                    if len(faces) > 1:\n",
    "                        ex = []\n",
    "                        print(type(faces))\n",
    "                        for elem in faces:\n",
    "                            for (x, y, w, h) in [elem]:\n",
    "                                ex.append(frame[y:y + h, x:x + w])\n",
    "\n",
    "\n",
    "                    for (x, y, w, h) in faces:\n",
    "                        face = frame[y:y + h, x:x + w]\n",
    "\n",
    "                    face = cv2.resize(face, (234, 234))\n",
    "                    face = face[5:-5, 5:-5]\n",
    "                    cv2.imwrite(os.path.join(output_path, f'{filename}_{count}.png'), face)\n",
    "                    \n",
    "                count += 1\n",
    "        finally:\n",
    "            cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4e2fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed videos 1/1440\n",
      "Processed videos 2/1440\n",
      "<class 'numpy.ndarray'>\n",
      "01-01-05-02-01-02-20\n",
      "Processed videos 3/1440\n",
      "<class 'numpy.ndarray'>\n",
      "02-01-05-02-01-02-20\n",
      "Processed videos 4/1440\n",
      "Processed videos 5/1440\n",
      "Processed videos 6/1440\n",
      "<class 'numpy.ndarray'>\n",
      "01-01-03-02-01-02-20\n",
      "Processed videos 7/1440\n",
      "Processed videos 8/1440\n",
      "Processed videos 9/1440\n",
      "Processed videos 10/1440\n",
      "Processed videos 11/1440\n",
      "Processed videos 12/1440\n",
      "Processed videos 13/1440\n",
      "Processed videos 14/1440\n",
      "Processed videos 15/1440\n",
      "Processed videos 16/1440\n",
      "Processed videos 17/1440\n",
      "Processed videos 18/1440\n",
      "Processed videos 19/1440\n",
      "Processed videos 20/1440\n",
      "Processed videos 21/1440\n",
      "Processed videos 22/1440\n",
      "Processed videos 23/1440\n",
      "Processed videos 24/1440\n",
      "Processed videos 25/1440\n",
      "Processed videos 26/1440\n",
      "Processed videos 27/1440\n",
      "Processed videos 28/1440\n",
      "Processed videos 29/1440\n",
      "Processed videos 30/1440\n",
      "Processed videos 31/1440\n",
      "Processed videos 32/1440\n",
      "Processed videos 33/1440\n",
      "Processed videos 34/1440\n",
      "Processed videos 35/1440\n"
     ]
    }
   ],
   "source": [
    "prepare_all_videos(filenames, paths, skip=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82fea806",
   "metadata": {},
   "source": [
    "### Mean face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d08ca70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_tras = {1:1, 2:4, 3:5, 4:0, 5:3, 6:2, 7:6}\n",
    "emotions = {0:'angry', 1:'calm', 2:'disgust', 3:'fear', 4:'happy', 5:'sad', 6:'surprise'}\n",
    "\n",
    "dataset_path = \"Datasets/RAVDESS_frames_face_BW/\"\n",
    "\n",
    "height_orig = 224\n",
    "width_orig = 224\n",
    "height_targ = 112\n",
    "width_targ = 112\n",
    "\n",
    "val_actors = ['19', '20']\n",
    "test_actors = ['21', '22', '23', '24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "79c9947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = [] # train\n",
    "\n",
    "for (dirpath, dirnames, fn) in os.walk(dataset_path):\n",
    "    if fn != []:\n",
    "        class_temp = int(fn[0].split('-')[2]) - 1\n",
    "        if class_temp != 0:                                                     # exclude 'neutral' label\n",
    "            if any(act in dirpath for act in (test_actors+val_actors))==False:  # select only train actors\n",
    "                path = [os.path.join(dirpath, elem) for elem in fn]\n",
    "                label = [emotions_tras[class_temp]] * len(fn)                   # emotion transposition\n",
    "                filenames_train.append(list(zip(path, label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "474408f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(list, num_frames_desired):\n",
    "    tot = []\n",
    "    for elem in list:\n",
    "        sampled_list = random.sample(elem, num_frames_desired)\n",
    "        tot += sampled_list\n",
    "    return(tot)\n",
    "\n",
    "\n",
    "def compute_mean_face(filenames):\n",
    "    # frames_per_vid = min([len(elem) for elem in filenames])     # number of frames per clip in order to have balanced classes\n",
    "    frames_per_vid = 20\n",
    "    print(\"frames per video:\", frames_per_vid) \n",
    "\n",
    "    filenames_sampled = sampling(filenames, frames_per_vid)\n",
    "    random.shuffle(filenames_sampled)\n",
    "\n",
    "    faces = []\n",
    "\n",
    "    for path, label in tqdm(filenames_sampled):\n",
    "        face = cv2.imread(path)\n",
    "        face = cv2.resize(face, (112, 112))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        faces.append(face)\n",
    "\n",
    "    faces = np.array(faces)\n",
    "    mean_face = np.mean(faces, axis=0)\n",
    "    mean_face = mean_face/255\n",
    "    mean_face = np.expand_dims(mean_face, axis=2)\n",
    "    np.save('Other/mean_face.npy', mean_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "636a0217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames per video: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35200/35200 [00:16<00:00, 2137.49it/s]\n"
     ]
    }
   ],
   "source": [
    "compute_mean_face(filenames_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe48f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
